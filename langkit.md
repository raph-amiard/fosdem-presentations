---
author:
- Pierre-Marie de Rodat
- Raphaël Amiard
title: Langkit
subtitle: source code analyzers for the masses
titlepage-note: |
 Title notes...
institute: Software Engineers at AdaCore
fontsize: 15pt
theme: metropolis
...

# Langkit: A meta compiler

## High level vision

A collection of DSLs to implement language parsing and analysis front ends.

Front ends generated by Langkit could be the basis for:

* compilers
* debuggers (e.g. expression evaluator)
* interactive code browsers
* static analyzers
* automatic code refactoring tools

## Original use case: Libadalang

* The Ada ecosystem lacks a good library to create code-aware tools
* Several half-backed analyzers in various tools (e.g. GPS, the main IDE)
* Libadalang = Langkit-generated library for Ada-aware tools

# The DSL

## Syntax

* Python-based DSL for now
* Uses the Python syntax to create data structures that are then compiled
* Will have its own syntax one day!

## DSL Episode 1: Lexing

```python
from langkit.lexer import LexerToken, WithText, WithSymbol

class MyTokens(LexerToken):
    Def = WithText()
    Identifier = WithSymbol()
    # ...

my_lexer = Lexer(MyTokens)
my_lexer.add_rules(
    (Literal('def'), MyTokens.Def),
    (Pattern(r'[a-zA-Z][a-zA-Z0-9]*',
     MyTokens.Identifier)),
    # ...
)
```

* Define a list of token kinds
* Provide regexp-based scanning rules to produce them

## DSL Episode 2: Tree

```python
from langkit.dsl import ASTNode, Field, abstract

@abstract
class RootNode(ASTNode):
    pass

class Name(RootNode):
    token_node = True

class Def(RootNode):
    name = Field()

# ...
```

* Define tree nodes the parser can produce
* Uses a Python class hierarchy to describe the *generated* node hierarchy
* Nodes can be abstract

## DSL Episode 3: Parsing

```python
from langkit.parsers import Grammar, List

g = Grammar('main_rule')
g.add_rules(
    main_rule=List(g.def_rule),
    name=Name(MyTokens.Identifier),
    def_rule=Def('def', g.name),
    # ...
)
```

* Recursive descent parser combinators (sequences, lists, optional parts,
  alternatives, ...), based on Packrat
* Compiling the grammar:
    - Infers node types `Field` if type not specified
    - Checks consistency otherwise

## DSL Episode 4: Scoping

```python
class Function(RootNode):
    local_vars = Field()
    env_spec = EnvSpec(
        add_env() # Associate an env to this node
    )

class VariableDeclaration(RootNode):
    name = Field()
    env_spec = EnvSpec(
        add_to_env(
            mappings=New(T.env_assoc, key=Self.name.symbol, val=Self)
            # In the current env, add a mapping from the name of this var to
            # the node itself.
        )
    )
```

* Foundation for semantic analysis
* Create name/nodes mappings: lexical environments

## DSL Episode 5: Semantic analysis

```python
from langkit.expressions import langkit_property

class VariableReference(FooNode):
    name = Field()

    @langkit_property(public=True)
    def var_decl():
        return Self.node_env.get_first(Self.name)
```

* Create methods on nodes (called "properties")
* Public properties: user API for semantic analysis
* Private ones: implementation detail, hidden from users
* Functional programming language

## DSL Episode 6: Logic DSL

- Hard problems in semantic analysis:
    * Overload resolution
    * Type inference
- Require non local knowledge

```ada
def F1 (I : int) -> int;
def F1 (F : float) -> int;

def F2 (C : char) -> int;
def F2 (C : char) -> char;

F1 (1);
F1 ('C');
F2 (2);

F1 (F2 (F2 ('C')));
```

## DSL Episode 6: Logic DSL

```ada
   F1 (F2 (F2 ('C')));
--         ^ Call A
--     ^ Call B
-- ^ Call C
```

```text
A.args[0].type = char
A.returns.type = B.args[0].type
B.returns.type = C.args[0].type
A is in [F2 (C : char) -> int,
         F2 (C : char) -> char]
B is in [F2 (C : char) -> int,
         F2 (C : char) -> char]
C is in [F1 (I : int) -> int,
         F1 (F : float) -> float]
```

## DSL Episode 6: Logic DSL

### TODO

# The generated libraries

## Base library: Ada (W00T!)

### Requirements for the target language:

- Fast
- Low level enough
- Memory management agnostic (no GC)
- Easy to bind to C and other languages

### Candidates

- C, C++, Ada, Rust, ...

### Chosen one: Ada

- Since the project is developed at AdaCore: no surprises :)

## Bindings to other languages

### Automatically generated C bindings

So that it is very easy to generate bindings to any languages the users wants

### First class citizen Python bindings

- Python is the de-facto scripting language of the Langkit ecosystem
- Everything possible in Ada is possible in Python

### Easy to generate bindings to new languages

- No need for external bindings generators
- Knowledge about data types, functions, memory management -> Langkit

## Crafted for incremental analysis

* Reloading happens a lot in IDE: performance required
* Avoid big recomputations for common operations
* No need to recompute *everything* when reloading one source file:
    * Keep source file-specific data as much isolated as possible
    * Reduced update process when removing/reloading source files

## Tree walking

Source code:
```python
a = 12
b = 15
print a + b
```

Processing:
```python
>>> for assign in unit.root.findall(lpl.AssignStmt):
>>>    print 'Stmt:', assign.text, assign.sloc_range

Stmt: a = 12 2:1-2:7
Stmt: b = 15 3:1-3:7
```

## Unparser

- Create a new source file *only from the tree* (not using original source
  information)
- Can also be used to create sources from completely synthetic trees
- Uses the grammar and the AST definition (no additional code needed)

## Rewriting (Work in progress)

Source code:
```ada
procedure Main is
begin
    Put_Line ("Hello world");
end Main;
```

Let's rewrite:
```python
call = unit.root.findall(lal.CallExpr) # Find the call
diff = ctx.start_rewriting() # Start a rewriting
param_diff = diff.get_node(call.f_suffix[0]) # Get the param of the call
# Replace the expression of the parameter with a new node
param_diff.f_expr = lal.rewriting.StringLiteral('"Bye world"')
diff.apply()
```

Result:
```ada
procedure Main is
begin
    Put_Line ("Bye world");
end Main;
```

# Generic tools shipping with the libraries

## Small tools

### ./playground

- Command line tool based on IPython
- Allow interactive exploration of the tree/API in general

### ./parse

- Allow inspection of the AST
- Dump lexical environments

## Code indenter (prototype)

- Provide a declarative data structure for indentation rules

```python
block_rule = field_rules(constant_increment=3)

indent_map = {
    lal.PackageDecl: Indent(
        field_rules=indent_fields(
            public_part=block_rule, private_part=block_rule
        )
    ),
    # ...
}
```

- Get auto indentation on tab in your favorite editor

## Syntax highlighter (not done)

- Auto generation of syntax highlighter
- Highlight keywords by default
- Custom rules to highlight more complex syntax based rules
- Automatic support in your editor

## Language server protocol? (not done)

- Tentative plan: automatically generate basic LSP support from the plug-in
- We have a Neovim plug-in already doing for Ada:
    - Indentation
    - Go to definition
    - Tree editing and exploration
- In the future: more editors, more languages?

## Existing langkit-based libraries & prototypes

- Ada
- Python
- JSON
- GPR files (AdaCore's project description language)
- KConfig

## Conclusion

- Sources are on GitHub: [https://github.com/AdaCore/langkit](https://github.com/AdaCore/langkit)
- Tutorial, too: [https://github.com/AdaCore/langkit/blob/master/doc/tutorial.rst](https://github.com/AdaCore/langkit/blob/master/doc/tutorial.rst)
- Still work in progress: APIs are moving and "doc is the code" (no separate
  documentation document)
- We gladly accept issues and pull requests, but our priority right now is
  Libadalang
